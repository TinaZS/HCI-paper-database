import json

#Replace with Select Paper to display on home page
data = {"results":[{"abstract":"Tactile charts are essential for conveying data to blind and low vision (BLV)\nreaders but are difficult for designers to construct. Non-expert designers face\nbarriers to entry due to complex guidelines, while experts struggle with\nfragmented and time-consuming workflows that involve extensive customization.\nInspired by formative interviews with expert tactile graphics designers, we\ncreated Tactile Vega-Lite (TVL): an extension of Vega-Lite that offers\ntactile-specific abstractions and synthesizes existing guidelines into a series\nof smart defaults. Predefined stylistic choices enable non-experts to produce\nguideline-compliant tactile charts quickly. Expert users can override defaults\nto tailor customizations for their intended audience. In a user study with 12\ntactile graphics creators, we show that Tactile Vega-Lite enhances flexibility\nand consistency by automating tasks like adjusting spacing and translating\nbraille while accelerating iterations through pre-defined textures and line\nstyles. Through expert critique, we also learn more about tactile chart design\nbest practices and design decisions.","datePublished":"2025-02-28T19:56:29Z","link":"http://arxiv.org/abs/2503.00149v2","paper_id":"376bb7aa-85a6-43fd-be34-a6572cbeb552","title":"Tactile Vega-Lite: Rapidly Prototyping Tactile Charts with Smart\n  Defaults"},{"abstract":"Accessible design for some may still produce barriers for others. This\ntension, called access friction, creates challenges for both designers and\nend-users with disabilities. To address this, we present the concept of\nsofterware, a system design approach that provides end users with agency to\nmeaningfully customize and adapt interfaces to their needs. To apply softerware\nto visualization, we assembled 195 data visualization customization options\ncentered on the barriers we expect users with disabilities will experience. We\nbuilt a prototype that applies a subset of these options and interviewed\npractitioners for feedback. Lastly, we conducted a design probe study with\nblind and low vision accessibility professionals to learn more about their\nchallenges and visions for softerware. We observed access frictions between our\nparticipant's designs and they expressed that for softerware's success, current\nand future systems must be designed with accessible defaults, interoperability,\npersistence, and respect for a user's perceived effort-to-outcome ratio.","datePublished":"2025-02-25T16:36:32Z","link":"http://arxiv.org/abs/2502.18348v1","paper_id":"8d40b1cb-73a7-4b9c-996d-3c91a926b0d5","title":"Towards softerware: Enabling personalization of interactive data\n  representations for users with disabilities"},{"abstract":"Previous work established that open source software (OSS) projects can\nbenefit from the involvement of UX professionals, who offer user-centric\nperspectives and contributions to improve software usability. However, their\nparticipation in OSS issue discussions (places where design and implementation\ndecisions are often made) is relatively scarce since those platforms are\ncreated with a developer-centric mindset. Analyzing a dataset sampled from five\nOSS projects, this study identifies UX professionals' distinct approaches to\nraising and following up on usability issues. Compared to other contributors,\nUX professionals addressed a broader range of usability issues, well-supported\ntheir stances, and were more factual than emotional. They also actively engage\nin discussions to provide additional insights and clarifications in comments\nfollowing up on the issues they posted. Results from this study provide useful\ninsights for increasing UX professionals' involvement in OSS communities to\nimprove usability and end-user satisfaction.","datePublished":"2025-02-24T15:45:13Z","link":"http://arxiv.org/abs/2502.17263v2","paper_id":"e30f5a24-f92b-4bc8-9d6d-898f0695d7c2","title":"Untold Stories: Unveiling the Scarce Contributions of UX Professionals\n  to Usability Issue Discussions of Open Source Software Projects"},{"abstract":"Testing Web User Interfaces (UIs) requires considerable time and effort and\nresources, most notably participants for user testing. Additionally, the tests\nresults may demand adjustments on the UI, taking further resources and testing.\nEarly tests can make this process less costly with the help of low fidelity\nprototypes, but it is difficult to conduct user tests on them, and recruiting\nparticipants is still necessary. To tackle this issue, there are tools that can\npredict UI aspects like interaction time, as the well-known KLM model. Another\naspect that can be predicted is complexity, and this was achieved by the Big I\nnotation, which can be applied to early UX concepts like lo-fi wireframes. Big\nI assists developers in estimating the interaction complexity, specified as a\nfunction of user steps, which are composed of abstracted user actions.\nInteraction complexity is expressed in mathematical terms, making the\ncomparison of interaction complexities for various UX concepts easy. However,\nbig I is not able to predict execution time for user actions, which would be\nvery helpful for early assessment of lo-fi prototypes. To address this\nshortcoming, in this paper we present a study in which we took measurements\nfrom real users (n=100) completing tasks in a fictitious website, in order to\nderive average times per interaction step. Using these results, we were able to\nstudy the relationship between interaction complexity and time and ultimately\ncomplement big I predictions with time estimates.","datePublished":"2025-02-20T23:25:35Z","link":"http://arxiv.org/abs/2502.15095v1","paper_id":"3e495794-35f0-4c4d-8710-f9f65436d2d7","title":"A Study on Interaction Complexity and Time"},{"abstract":"Usability testing is a fundamental yet challenging (e.g., inflexible to\niterate the study design flaws and hard to recruit study participants) research\nmethod for user experience (UX) researchers to evaluate a web design. Recent\nadvances in Large Language Model-simulated Agent (LLM-Agent) research inspired\nus to design UXAgent to support UX researchers in evaluating and reiterating\ntheir usability testing study design before they conduct the real human subject\nstudy. Our system features an LLM-Agent module and a universal browser\nconnector module so that UX researchers can automatically generate thousands of\nsimulated users to test the target website. The results are shown in\nqualitative (e.g., interviewing how an agent thinks ), quantitative (e.g., # of\nactions), and video recording formats for UX researchers to analyze. Through a\nheuristic user evaluation with five UX researchers, participants praised the\ninnovation of our system but also expressed concerns about the future of LLM\nAgent-assisted UX study.","datePublished":"2025-02-18T05:55:18Z","link":"http://arxiv.org/abs/2502.12561v2","paper_id":"fe37d574-e625-4ba5-a056-dbcf1889697c","title":"UXAgent: An LLM Agent-Based Usability Testing Framework for Web Design"},{"abstract":"We present clinguin, a system for ASP-driven user interface design. Clinguin\nstreamlines the development of user interfaces for ASP developers by letting\nthem build interactive prototypes directly in ASP, eliminating the need for\nseparate frontend languages. To this end, clinguin uses a few dedicated\npredicates to define user interfaces and the treatment of user-triggered\nevents. This simple design greatly facilitates the specification of user\ninteractions with an ASP system, in our case clingo.","datePublished":"2025-02-13T11:50:51Z","link":"http://arxiv.org/abs/2502.09222v1","paper_id":"fb6662e1-a83d-441a-967b-732e30043875","title":"ASP-driven User-interaction with Clinguin"}]}

formatted_data = []

for item in data["results"]:
    formatted_data.append({
        "title": item["title"],
        "abstract": item["abstract"],
        "datePublished": item["datePublished"].split("T")[0],  # Only keep date part
        "link": item["link"], 
        "paper_id": item["paper_id"]
    })

print(json.dumps(formatted_data, indent=2))